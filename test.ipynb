{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def handle_parentheses(query):\n",
    "    def replace_match(m):\n",
    "        inner = m.group(1)\n",
    "        return f\"(?:{process_query(inner)})\"\n",
    "\n",
    "    # Handle innermost parentheses first\n",
    "    def process_innermost_parentheses(q):\n",
    "        return re.sub(r\"\\(([^()]+)\\)\", lambda m: f\"(?:{process_query(m.group(1))})\", q)\n",
    "    \n",
    "    # Iteratively handle nested parentheses\n",
    "    previous_query = None\n",
    "    while previous_query != query:\n",
    "        previous_query = query\n",
    "        query = process_innermost_parentheses(query)\n",
    "        # Handle cases with nested parentheses\n",
    "        query = re.sub(\n",
    "            r\"\\(([^()]*\\([^()]*\\)[^()]*)\\)\",\n",
    "            lambda m: f\"(?:{process_query(m.group(1))})\",\n",
    "            query,\n",
    "        )\n",
    "        query = process_innermost_parentheses(query)\n",
    "        \n",
    "    return query\n",
    "\n",
    "# Example usage\n",
    "query = \"\"\"(((protect* OR care OR caring OR safe* OR shield* OR defend* OR guard* OR defens*) NEAR/3 (sun OR UV OR UVA OR UVB OR solar)) OR \"anti-sun\" OR \"anti sun\")\"\"\"\n",
    "\n",
    "# Convert the query to regex pattern\n",
    "pattern = process_query(query)\n",
    "print(f\"Generated regex pattern: {pattern}\")\n",
    "\n",
    "# Apply regex to rows\n",
    "for row in rows:\n",
    "    if re.search(pattern, row, re.IGNORECASE):\n",
    "        print(f\"Match found: {row}\")\n",
    "    else:\n",
    "        print(f\"No match: {row}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((BB|\\bBeauty\\ Balm\\b|\\bBlemish\\ Balm\\b|\\bbeauty\\-balm\\b|\\bblemish\\-balm\\b ^(?!.blu)) NEAR/2 (cream|creams)).*Nice\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Sample data (rows)\n",
    "rows = [\n",
    "    \"I love chocolate and vanilla ice cream Beauty Balm.\",\n",
    "    \"Blue and green are my favorite colors.\",\n",
    "    \"Taste is subjective, but I prefer optimize over optimise.\",\n",
    "    \"Mentioning @doveuk here, and #blue for hashtags.\",\n",
    "]\n",
    "\n",
    "# Example query\n",
    "query = \"\"\"((BB OR \"Beauty Balm\" OR \"Blemish Balm\" OR \"beauty-balm\" OR \"blemish-balm\" NOT blue) NEAR/2 (cream OR creams)) AND Nice\"\"\"\n",
    "\n",
    "\n",
    "def handle_or(query):\n",
    "    return query.replace(\" OR \", \"|\")\n",
    "\n",
    "\n",
    "def handle_and(query):\n",
    "    return query.replace(\" AND \", \".*\")\n",
    "\n",
    "\n",
    "def handle_not(query):\n",
    "    return re.sub(r\"NOT\\s+(\\w+)\", r\"^(?!.*\\b\\1\\b)\", query)\n",
    "\n",
    "\n",
    "def handle_exact_phrases(query):\n",
    "    # Replace exact phrases inside double quotes with regex pattern\n",
    "    return re.sub(r'\"(.*?)\"', lambda m: r\"\\b\" + re.escape(m.group(1)) + r\"\\b\", query)\n",
    "\n",
    "\n",
    "def handle_near_x(query):\n",
    "    near_pattern = re.compile(r'(\\w+|\"[^\"]*\")\\s+NEAR/(\\d+)\\s+(\\w+|\"[^\"]*\")')\n",
    "    while near_pattern.search(query):\n",
    "        match = near_pattern.search(query)\n",
    "        term1, distance, term2 = match.groups()\n",
    "        term1 = term1.strip('\"')\n",
    "        term2 = term2.strip('\"')\n",
    "        pattern = r\"\\b{}\\b(?:\\W+\\w+){{0,{}}}\\W+\\b{}\\b\".format(\n",
    "            term1, int(distance), term2\n",
    "        )\n",
    "        query = near_pattern.sub(pattern, query, 1)\n",
    "    return query\n",
    "\n",
    "\n",
    "def handle_wildcards(query):\n",
    "    return re.sub(r\"(\\w+)\\*\", r\"\\1.*\", query)\n",
    "\n",
    "\n",
    "def handle_question_marks(query):\n",
    "    return re.sub(r\"(\\w+)\\?\", lambda m: f\"{m.group(1)}.\", query)\n",
    "\n",
    "\n",
    "def handle_mentions(query):\n",
    "    return re.sub(r\"at_mention:\\((.*?)\\)\", r\"@\\b\\1\\b\", query)\n",
    "\n",
    "\n",
    "def handle_hashtags(query):\n",
    "    return re.sub(r\"hashtag:\\((.*?)\\)\", r\"#\\b\\1\\b\", query)\n",
    "\n",
    "\n",
    "def process_inner_parentheses(query):\n",
    "    # Process innermost parentheses first\n",
    "    def replace_match(m):\n",
    "        inner = m.group(1)\n",
    "        return f\"(?:{process_query(inner)})\"\n",
    "\n",
    "    return re.sub(r\"\\(([^()]+)\\)\", replace_match, query)\n",
    "\n",
    "\n",
    "def handle_parentheses(query):\n",
    "    # Recursively handle parentheses\n",
    "    previous_query = None\n",
    "    while previous_query != query:\n",
    "        previous_query = query\n",
    "        query = process_inner_parentheses(query)\n",
    "        # Handle cases where there may be nested parentheses\n",
    "        query = re.sub(\n",
    "            r\"\\(([^()]*\\([^()]*\\)[^()]*)\\)\",\n",
    "            lambda m: f\"(?:{process_query(m.group(1))})\",\n",
    "            query,\n",
    "        )\n",
    "    return query\n",
    "\n",
    "\n",
    "def process_query(query):\n",
    "    query = handle_or(query)\n",
    "    query = handle_and(query)\n",
    "    query = handle_not(query)\n",
    "    query = handle_exact_phrases(query)\n",
    "    query = handle_parentheses(query)\n",
    "    query = handle_near_x(query)\n",
    "    query = handle_wildcards(query)\n",
    "    query = handle_question_marks(query)\n",
    "    query = handle_mentions(query)\n",
    "    query = handle_hashtags(query)\n",
    "    return query\n",
    "\n",
    "\n",
    "query = handle_or(query)\n",
    "query = handle_and(query)\n",
    "query = handle_not(query)\n",
    "query = handle_exact_phrases(query)\n",
    "print(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated regex pattern: (?:BB|\\bBeauty\\ Balm\\b|\\bBlemish\\ Balm\\b|\\bbeauty\\-balm\\b|\\bblemish\\-balm\\b) NEAR/2 (?:cream|creams)\n",
      "No match: I love chocolate and vanilla ice cream Beauty Balm.\n",
      "No match: Blue and green are my favorite colors.\n",
      "No match: Taste is subjective, but I prefer optimize over optimise.\n",
      "No match: Mentioning @doveuk here, and #blue for hashtags.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def handle_or(query):\n",
    "    return query.replace(\" OR \", \"|\")\n",
    "\n",
    "def handle_and(query):\n",
    "    return query.replace(\" AND \", \".*\")\n",
    "\n",
    "def handle_not(query):\n",
    "    return re.sub(r\"NOT\\s+(\\w+)\", r\"^(?!.*\\b\\1\\b)\", query)\n",
    "\n",
    "def handle_exact_phrases(query):\n",
    "    return re.sub(r'\"(.*?)\"', lambda m: r\"\\b\" + re.escape(m.group(1)) + r\"\\b\", query)\n",
    "\n",
    "\n",
    "def handle_near_x(query):\n",
    "    # Define a regex pattern to match the NEAR/x operator in the query\n",
    "    near_pattern = re.compile(r'\\((\\w+|\"[^\"]*\")\\s+NEAR/(\\d+)\\s+(\\w+|\"[^\"]*\")\\)')\n",
    "\n",
    "    # Iterate over all NEAR/x matches in the query\n",
    "    while near_pattern.search(query):\n",
    "        match = near_pattern.search(query)\n",
    "        term1, distance, term2 = match.groups()\n",
    "\n",
    "        # Strip quotes from the terms\n",
    "        term1 = term1.strip('\"')\n",
    "        term2 = term2.strip('\"')\n",
    "\n",
    "        # Create a regex pattern for the NEAR/x operator\n",
    "        pattern = r'\\b{}\\b(?:\\W+\\w+){{0,{}}}\\W+\\b{}\\b'.format(\n",
    "            re.escape(term1), int(distance), re.escape(term2)\n",
    "        )\n",
    "\n",
    "        # Replace the NEAR/x pattern in the query with the generated regex pattern\n",
    "        query = near_pattern.sub(pattern, query, 1)\n",
    "\n",
    "    return query\n",
    "\n",
    "def handle_wildcards(query):\n",
    "    return re.sub(r\"(\\w+)\\*\", r\"\\1.*\", query)\n",
    "\n",
    "def handle_question_marks(query):\n",
    "    return re.sub(r\"(\\w+)\\?\", lambda m: f\"{m.group(1)}.\", query)\n",
    "\n",
    "def handle_mentions(query):\n",
    "    return re.sub(r\"at_mention:\\((.*?)\\)\", r\"@\\b\\1\\b\", query)\n",
    "\n",
    "def handle_hashtags(query):\n",
    "    return re.sub(r\"hashtag:\\((.*?)\\)\", r\"#\\b\\1\\b\", query)\n",
    "\n",
    "def handle_parentheses(query):\n",
    "    def process_subquery(subquery):\n",
    "        # Apply transformations directly here\n",
    "        subquery = handle_or(subquery)\n",
    "        subquery = handle_and(subquery)\n",
    "        subquery = handle_not(subquery)\n",
    "        subquery = handle_exact_phrases(subquery)\n",
    "        subquery = handle_near_x(subquery)\n",
    "        subquery = handle_wildcards(subquery)\n",
    "        subquery = handle_question_marks(subquery)\n",
    "        subquery = handle_mentions(subquery)\n",
    "        subquery = handle_hashtags(subquery)\n",
    "        return subquery\n",
    "\n",
    "    stack = []\n",
    "    current_query = \"\"\n",
    "\n",
    "    i = 0\n",
    "    while i < len(query):\n",
    "        if query[i] == \"(\":\n",
    "            # Push current query and position onto the stack\n",
    "            stack.append((current_query, i))\n",
    "            current_query = \"\"\n",
    "        elif query[i] == \")\":\n",
    "            # Pop from stack and handle the content inside parentheses\n",
    "            last_query, start_pos = stack.pop()\n",
    "            subquery = query[start_pos + 1 : i]\n",
    "            # Process the subquery and add it to the current query\n",
    "            processed_subquery = process_subquery(subquery)\n",
    "            current_query = last_query + f\"(?:{processed_subquery})\"\n",
    "        else:\n",
    "            current_query += query[i]\n",
    "        i += 1\n",
    "\n",
    "    return current_query\n",
    "\n",
    "def process_query(query):\n",
    "    query = handle_parentheses(query)\n",
    "    query = handle_or(query)\n",
    "    query = handle_and(query)\n",
    "    query = handle_not(query)\n",
    "    query = handle_exact_phrases(query)\n",
    "    query = handle_near_x(query)\n",
    "    query = handle_wildcards(query)\n",
    "    query = handle_question_marks(query)\n",
    "    query = handle_mentions(query)\n",
    "    query = handle_hashtags(query)\n",
    "    return query\n",
    "\n",
    "# Example usage\n",
    "query = '''(BB OR \"Beauty Balm\" OR \"Blemish Balm\" OR \"beauty-balm\" OR \"blemish-balm\") NEAR/2 (cream OR creams)'''\n",
    "\n",
    "# Convert query to regex pattern\n",
    "pattern = process_query(query)\n",
    "print(f\"Generated regex pattern: {pattern}\")\n",
    "\n",
    "# Sample data (rows)\n",
    "rows = [\n",
    "    \"I love chocolate and vanilla ice cream Beauty Balm.\",\n",
    "    \"Blue and green are my favorite colors.\",\n",
    "    \"Taste is subjective, but I prefer optimize over optimise.\",\n",
    "    \"Mentioning @doveuk here, and #blue for hashtags.\",\n",
    "]\n",
    "\n",
    "# Apply regex to rows\n",
    "for row in rows:\n",
    "    if re.search(pattern, row, re.IGNORECASE):  # Added re.IGNORECASE for case-insensitive matching\n",
    "        print(f\"Match found: {row}\")\n",
    "    else:\n",
    "        print(f\"No match: {row}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-fc41b169f4a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;31m# Convert query to regex pattern\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m \u001b[0mpattern\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocess_query\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Generated regex pattern: {pattern}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-fc41b169f4a3>\u001b[0m in \u001b[0;36mprocess_query\u001b[1;34m(query)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mprocess_query\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m     \u001b[0mquery\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandle_parentheses\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m     \u001b[0mquery\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandle_or\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[0mquery\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandle_and\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-fc41b169f4a3>\u001b[0m in \u001b[0;36mhandle_parentheses\u001b[1;34m(query)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;31m# Handle nested parentheses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;34m'('\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mquery\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m         \u001b[0mquery\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'\\(([^()]*\\([^()]*\\)[^()]*)\\)'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplace_match\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;31m# Final processing of any remaining unprocessed content\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def handle_or(query):\n",
    "    return query.replace(\" OR \", \"|\")\n",
    "\n",
    "def handle_and(query):\n",
    "    return query.replace(\" AND \", \".*\")\n",
    "\n",
    "def handle_not(query):\n",
    "    return re.sub(r\"NOT\\s+(\\w+)\", r\"^(?!.*\\b\\1\\b)\", query)\n",
    "\n",
    "def handle_exact_phrases(query):\n",
    "    return re.sub(r'\"(.*?)\"', lambda m: r\"\\b\" + re.escape(m.group(1)) + r\"\\b\", query)\n",
    "\n",
    "def handle_near_x(query):\n",
    "    def replace_near(match):\n",
    "        term1, distance, term2 = match.groups()\n",
    "        term1 = term1.strip('\"')\n",
    "        term2 = term2.strip('\"')\n",
    "        return r\"\\b{}\\b(?:\\W+\\w+){{0,{}}}\\W+\\b{}\\b\".format(term1, int(distance), term2)\n",
    "    \n",
    "    near_pattern = re.compile(r'(\\w+|\"[^\"]*\")\\s+NEAR/(\\d+)\\s+(\\w+|\"[^\"]*\")')\n",
    "    return near_pattern.sub(replace_near, query)\n",
    "\n",
    "def handle_wildcards(query):\n",
    "    return re.sub(r\"(\\w+)\\*\", r\"\\1.*\", query)\n",
    "\n",
    "def handle_question_marks(query):\n",
    "    return re.sub(r\"(\\w+)\\?\", lambda m: f\"{m.group(1)}.\", query)\n",
    "\n",
    "def handle_mentions(query):\n",
    "    return re.sub(r\"at_mention:\\((.*?)\\)\", r\"@\\b\\1\\b\", query)\n",
    "\n",
    "def handle_hashtags(query):\n",
    "    return re.sub(r\"hashtag:\\((.*?)\\)\", r\"#\\b\\1\\b\", query)\n",
    "\n",
    "def process_subquery(subquery):\n",
    "    # Apply transformations directly here\n",
    "    subquery = handle_or(subquery)\n",
    "    subquery = handle_and(subquery)\n",
    "    subquery = handle_not(subquery)\n",
    "    subquery = handle_exact_phrases(subquery)\n",
    "    subquery = handle_near_x(subquery)\n",
    "    subquery = handle_wildcards(subquery)\n",
    "    subquery = handle_question_marks(subquery)\n",
    "    subquery = handle_mentions(subquery)\n",
    "    subquery = handle_hashtags(subquery)\n",
    "    return subquery\n",
    "\n",
    "def handle_parentheses(query):\n",
    "    def replace_match(m):\n",
    "        inner = m.group(1)\n",
    "        return f\"(?:{process_subquery(inner)})\"\n",
    "\n",
    "    # Process innermost parentheses first\n",
    "    query = re.sub(r'\\(([^()]+)\\)', replace_match, query)\n",
    "\n",
    "    # Handle nested parentheses\n",
    "    while '(' in query:\n",
    "        query = re.sub(r'\\(([^()]*\\([^()]*\\)[^()]*)\\)', replace_match, query)\n",
    "    \n",
    "    # Final processing of any remaining unprocessed content\n",
    "    return process_subquery(query)\n",
    "\n",
    "def process_query(query):\n",
    "    query = handle_parentheses(query)\n",
    "    query = handle_or(query)\n",
    "    query = handle_and(query)\n",
    "    query = handle_not(query)\n",
    "    query = handle_exact_phrases(query)\n",
    "    query = handle_near_x(query)\n",
    "    query = handle_wildcards(query)\n",
    "    query = handle_question_marks(query)\n",
    "    query = handle_mentions(query)\n",
    "    query = handle_hashtags(query)\n",
    "    return query\n",
    "\n",
    "# Example usage\n",
    "query = \"\"\"(((protect* OR care OR caring OR safe* OR shield* OR defend* OR guard* OR defens*) NEAR/3 (sun OR UV OR UVA OR UVB OR solar)) OR \"anti-sun\" OR \"anti sun\")\"\"\"\n",
    "\n",
    "# Convert query to regex pattern\n",
    "pattern = process_query(query)\n",
    "print(f\"Generated regex pattern: {pattern}\")\n",
    "\n",
    "# Sample data (rows)\n",
    "rows = [\n",
    "    \"I love chocolate and vanilla ice cream Beauty Balm.\",\n",
    "    \"Blue and green are my favorite colors.\",\n",
    "    \"Taste is subjective, but I prefer optimize over optimise.\",\n",
    "    \"Mentioning @doveuk here, and #blue for hashtags.\",\n",
    "]\n",
    "\n",
    "# Apply regex to rows\n",
    "for row in rows:\n",
    "    if re.search(pattern, row, re.IGNORECASE):  # Added re.IGNORECASE for case-insensitive matching\n",
    "        print(f\"Match found: {row}\")\n",
    "    else:\n",
    "        print(f\"No match: {row}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "bad escape \\W at position 91",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\KRILLIN\\anaconda3\\lib\\sre_parse.py\u001b[0m in \u001b[0;36mparse_template\u001b[1;34m(source, state)\u001b[0m\n\u001b[0;32m   1038\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                     \u001b[0mthis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mESCAPES\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1040\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '\\\\W'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-1a26a369b9bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;31m# Example usage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[0mquery\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\"\"(protect* OR care OR caring OR safe* OR shield* OR defend* OR guard* OR defens*) NEAR/3 (sun OR UV OR UVA OR UVB OR solar)\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[0mconverted_query\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandle_near_x\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Converted query: {converted_query}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-1a26a369b9bd>\u001b[0m in \u001b[0;36mhandle_near_x\u001b[1;34m(query)\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mregex_pattern\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_near_pattern\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlhs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrhs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;31m# Replace NEAR/x pattern in the query with the regex pattern\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         query = re.sub(r'\\(\\s*{}\\s+NEAR/{}\\s+{}\\s*\\)'.format(re.escape(lhs), distance, re.escape(rhs)), \n\u001b[0m\u001b[0;32m     35\u001b[0m                        regex_pattern, query, flags=re.UNICODE)\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\KRILLIN\\anaconda3\\lib\\re.py\u001b[0m in \u001b[0;36msub\u001b[1;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[0ma\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mMatch\u001b[0m \u001b[0mobject\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mmust\u001b[0m \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m     a replacement string to be used.\"\"\"\n\u001b[1;32m--> 210\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msubn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\KRILLIN\\anaconda3\\lib\\re.py\u001b[0m in \u001b[0;36m_subx\u001b[1;34m(pattern, template)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_subx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemplate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m     \u001b[1;31m# internal: Pattern.sub/subn implementation helper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 327\u001b[1;33m     \u001b[0mtemplate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_compile_repl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    328\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtemplate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m         \u001b[1;31m# literal replacement\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\KRILLIN\\anaconda3\\lib\\re.py\u001b[0m in \u001b[0;36m_compile_repl\u001b[1;34m(repl, pattern)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_compile_repl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[1;31m# internal: compile replacement pattern\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 318\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0msre_parse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_template\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_expand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemplate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\KRILLIN\\anaconda3\\lib\\sre_parse.py\u001b[0m in \u001b[0;36mparse_template\u001b[1;34m(source, state)\u001b[0m\n\u001b[0;32m   1040\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mASCIILETTERS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1042\u001b[1;33m                         \u001b[1;32mraise\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'bad escape %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mthis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1043\u001b[0m                 \u001b[0mlappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: bad escape \\W at position 91"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def handle_near_x(query):\n",
    "    \"\"\"\n",
    "    Converts NEAR/x patterns in the query into regex.\n",
    "    :param query: The query containing NEAR/x patterns\n",
    "    :return: The query with NEAR/x patterns converted to regex\n",
    "    \"\"\"\n",
    "    def convert_near_pattern(lhs, distance, rhs):\n",
    "        \"\"\"\n",
    "        Converts a NEAR/x pattern to a regex pattern.\n",
    "        :param lhs: Left-hand side of the NEAR/x pattern\n",
    "        :param distance: Distance for the NEAR operator\n",
    "        :param rhs: Right-hand side of the NEAR/x pattern\n",
    "        :return: The regex pattern for the NEAR/x pattern\n",
    "        \"\"\"\n",
    "        # Convert wildcards and question marks to regex\n",
    "        lhs_regex = re.sub(r'\\*', '.*', lhs)\n",
    "        rhs_regex = re.sub(r'\\*', '.*', rhs)\n",
    "        lhs_regex = re.sub(r'\\?', '.', lhs_regex)\n",
    "        rhs_regex = re.sub(r'\\?', '.', rhs_regex)\n",
    "\n",
    "        # Construct regex pattern for NEAR/x\n",
    "        return r'\\b{}\\b(?:\\W+\\w+){{0,{}}}\\W+\\b{}\\b'.format(lhs_regex, distance, rhs_regex)\n",
    "\n",
    "    # Find all NEAR/x patterns\n",
    "    near_pattern = re.compile(r'\\(([^()]+)\\)\\s+NEAR/(\\d+)\\s+\\(([^()]+)\\)')\n",
    "    matches = near_pattern.findall(query)\n",
    "\n",
    "    for lhs, distance, rhs in matches:\n",
    "        # Convert NEAR/x pattern to regex\n",
    "        regex_pattern = convert_near_pattern(lhs, int(distance), rhs)\n",
    "        # Replace NEAR/x pattern in the query with the regex pattern\n",
    "        query = re.sub(r'\\(\\s*{}\\s+NEAR/{}\\s+{}\\s*\\)'.format(re.escape(lhs), distance, re.escape(rhs)), \n",
    "                       regex_pattern, query, flags=re.UNICODE)\n",
    "\n",
    "    return query\n",
    "\n",
    "# Example usage\n",
    "query = \"\"\"(protect* OR care OR caring OR safe* OR shield* OR defend* OR guard* OR defens*) NEAR/3 (sun OR UV OR UVA OR UVB OR solar)\"\"\"\n",
    "converted_query = handle_near_x(query)\n",
    "print(f\"Converted query: {converted_query}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "bad escape \\W at position 91",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\KRILLIN\\anaconda3\\lib\\sre_parse.py\u001b[0m in \u001b[0;36mparse_template\u001b[1;34m(source, state)\u001b[0m\n\u001b[0;32m   1038\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                     \u001b[0mthis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mESCAPES\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1040\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '\\\\W'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-824945f2182c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;31m# Example usage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[0mquery\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\"\"(protect* OR care OR caring OR safe* OR shield* OR defend* OR guard* OR defens*) NEAR/3 (sun OR UV OR UVA OR UVB OR solar)\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m \u001b[0mconverted_query\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandle_near_x\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Converted query: {converted_query}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-824945f2182c>\u001b[0m in \u001b[0;36mhandle_near_x\u001b[1;34m(query)\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mrhs_escaped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mescape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrhs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;31m# Replace NEAR/x pattern in the query with the regex pattern\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         query = re.sub(r'\\(\\s*{}\\s+NEAR/{}\\s+{}\\s*\\)'.format(lhs_escaped, distance, rhs_escaped), \n\u001b[0m\u001b[0;32m     38\u001b[0m                        regex_pattern, query, flags=re.UNICODE)\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\KRILLIN\\anaconda3\\lib\\re.py\u001b[0m in \u001b[0;36msub\u001b[1;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[0ma\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mMatch\u001b[0m \u001b[0mobject\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mmust\u001b[0m \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m     a replacement string to be used.\"\"\"\n\u001b[1;32m--> 210\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msubn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\KRILLIN\\anaconda3\\lib\\re.py\u001b[0m in \u001b[0;36m_subx\u001b[1;34m(pattern, template)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_subx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemplate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m     \u001b[1;31m# internal: Pattern.sub/subn implementation helper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 327\u001b[1;33m     \u001b[0mtemplate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_compile_repl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    328\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtemplate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m         \u001b[1;31m# literal replacement\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\KRILLIN\\anaconda3\\lib\\re.py\u001b[0m in \u001b[0;36m_compile_repl\u001b[1;34m(repl, pattern)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_compile_repl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[1;31m# internal: compile replacement pattern\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 318\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0msre_parse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_template\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_expand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemplate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\KRILLIN\\anaconda3\\lib\\sre_parse.py\u001b[0m in \u001b[0;36mparse_template\u001b[1;34m(source, state)\u001b[0m\n\u001b[0;32m   1040\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mASCIILETTERS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1042\u001b[1;33m                         \u001b[1;32mraise\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'bad escape %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mthis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1043\u001b[0m                 \u001b[0mlappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: bad escape \\W at position 91"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def handle_near_x(query):\n",
    "    \"\"\"\n",
    "    Converts NEAR/x patterns in the query into regex.\n",
    "    :param query: The query containing NEAR/x patterns\n",
    "    :return: The query with NEAR/x patterns converted to regex\n",
    "    \"\"\"\n",
    "    def convert_near_pattern(lhs, distance, rhs):\n",
    "        \"\"\"\n",
    "        Converts a NEAR/x pattern to a regex pattern.\n",
    "        :param lhs: Left-hand side of the NEAR/x pattern\n",
    "        :param distance: Distance for the NEAR operator\n",
    "        :param rhs: Right-hand side of the NEAR/x pattern\n",
    "        :return: The regex pattern for the NEAR/x pattern\n",
    "        \"\"\"\n",
    "        # Convert wildcards and question marks to regex\n",
    "        lhs_regex = re.sub(r'\\*', '.*', lhs)\n",
    "        rhs_regex = re.sub(r'\\*', '.*', rhs)\n",
    "        lhs_regex = re.sub(r'\\?', '.', lhs_regex)\n",
    "        rhs_regex = re.sub(r'\\?', '.', rhs_regex)\n",
    "\n",
    "        # Construct regex pattern for NEAR/x\n",
    "        return r'\\b{}\\b(?:\\W+\\w+){{0,{}}}\\W+\\b{}\\b'.format(lhs_regex, distance, rhs_regex)\n",
    "\n",
    "    # Find all NEAR/x patterns\n",
    "    near_pattern = re.compile(r'\\(([^()]+)\\)\\s+NEAR/(\\d+)\\s+\\(([^()]+)\\)')\n",
    "    matches = near_pattern.findall(query)\n",
    "\n",
    "    for lhs, distance, rhs in matches:\n",
    "        # Convert NEAR/x pattern to regex\n",
    "        regex_pattern = convert_near_pattern(lhs, int(distance), rhs)\n",
    "        # Escape special regex characters in lhs and rhs\n",
    "        lhs_escaped = re.escape(lhs)\n",
    "        rhs_escaped = re.escape(rhs)\n",
    "        # Replace NEAR/x pattern in the query with the regex pattern\n",
    "        query = re.sub(r'\\(\\s*{}\\s+NEAR/{}\\s+{}\\s*\\)'.format(lhs_escaped, distance, rhs_escaped), \n",
    "                       regex_pattern, query, flags=re.UNICODE)\n",
    "\n",
    "    return query\n",
    "\n",
    "# Example usage\n",
    "query = \"\"\"(protect* OR care OR caring OR safe* OR shield* OR defend* OR guard* OR defens*) NEAR/3 (sun OR UV OR UVA OR UVB OR solar)\"\"\"\n",
    "converted_query = handle_near_x(query)\n",
    "print(f\"Converted query: {converted_query}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regex Pattern: \\bblue\\b(?:\\W+\\w+){0,2}\\W+\\bgreen\\b|\\bgreen\\b(?:\\W+\\w+){0,2}\\W+\\bblue\\b\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def convert_near_pattern(lhs, distance, rhs):\n",
    "    lhs_regex = re.sub(r'\\*', '.*', lhs)\n",
    "    rhs_regex = re.sub(r'\\*', '.*', rhs)\n",
    "    lhs_regex = re.sub(r'\\?', '.', lhs_regex)\n",
    "    rhs_regex = re.sub(r'\\?', '.', rhs_regex)\n",
    "    \n",
    "    return r'\\b{}\\b(?:\\W+\\w+){{0,{}}}\\W+\\b{}\\b|\\b{}\\b(?:\\W+\\w+){{0,{}}}\\W+\\b{}\\b'.format(\n",
    "        lhs_regex, distance, rhs_regex, rhs_regex, distance, lhs_regex\n",
    "    )\n",
    "\n",
    "# Example usage\n",
    "query = \"blue NEAR/2 green\"\n",
    "lhs, distance, rhs = \"blue\", 2, \"green\"\n",
    "regex_pattern = convert_near_pattern(lhs, distance, rhs)\n",
    "print(f\"Regex Pattern: {regex_pattern}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "near_pattern = re.compile(\n",
    "    r'\\(\\s*(.*?)\\s+NEAR/(\\d+)\\s+(.*?)\\s*\\)',\n",
    "    re.IGNORECASE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def has_near_operator(query):\n",
    "    # Regex pattern to find NEAR/x operator\n",
    "    near_pattern = re.compile(r'NEAR/\\d+', re.IGNORECASE)\n",
    "    \n",
    "    # Search for the pattern in the query\n",
    "    if near_pattern.search(query):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# Example usage\n",
    "query1 = '''(BB OR \"Beauty Balm\" OR \"Blemish Balm\" OR \"beauty-balm\" OR \"blemish-balm\") NEAR/2 (cream OR creams)'''\n",
    "query2 = \"This query has no near operator\"\n",
    "\n",
    "print(has_near_operator(query1))  # Output: True\n",
    "print(has_near_operator(query2))  # Output: False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated regex pattern: (?:BB|\\bBeauty\\ Balm\\b|\\bBlemish\\ Balm\\b|\\bbeauty\\-balm\\b|\\bblemish\\-balm\\b) NEAR/2 (?:cream|creams)\n",
      "No match: I love chocolate and vanilla ice cream Beauty Balm.\n",
      "No match: Blue and green are my favorite colors.\n",
      "No match: Taste is subjective, but I prefer optimize over optimise.\n",
      "No match: Mentioning @doveuk here, and #blue for hashtags.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def handle_or(query):\n",
    "    return query.replace(\" OR \", \"|\")\n",
    "\n",
    "def handle_and(query):\n",
    "    return query.replace(\" AND \", \".*\")\n",
    "\n",
    "def handle_not(query):\n",
    "    return re.sub(r\"NOT\\s+(\\w+)\", r\"^(?!.*\\b\\1\\b)\", query)\n",
    "\n",
    "def handle_exact_phrases(query):\n",
    "    return re.sub(r'\"(.*?)\"', lambda m: r\"\\b\" + re.escape(m.group(1)) + r\"\\b\", query)\n",
    "\n",
    "def handle_near_x(query):\n",
    "    # Define a regex pattern to match the NEAR/x operator in the query\n",
    "    near_pattern = re.compile(r'\\((\\w+|\"[^\"]*\")\\s+NEAR/(\\d+)\\s+(\\w+|\"[^\"]*\")\\)')\n",
    "\n",
    "    while near_pattern.search(query):\n",
    "        match = near_pattern.search(query)\n",
    "        term1, distance, term2 = match.groups()\n",
    "        term1 = term1.strip('\"')\n",
    "        term2 = term2.strip('\"')\n",
    "        # Create a regex pattern for the NEAR/x operator\n",
    "        pattern = r'\\b{}\\b(?:\\W+\\w+){{0,{}}}\\W+\\b{}\\b'.format(\n",
    "            re.escape(term1), int(distance), re.escape(term2)\n",
    "        )\n",
    "        # Replace the NEAR/x pattern in the query with the generated regex pattern\n",
    "        query = near_pattern.sub(pattern, query, 1)\n",
    "\n",
    "    return query\n",
    "\n",
    "def handle_wildcards(query):\n",
    "    return re.sub(r\"(\\w+)\\*\", r\"\\1.*\", query)\n",
    "\n",
    "def handle_question_marks(query):\n",
    "    return re.sub(r\"(\\w+)\\?\", lambda m: f\"{m.group(1)}.\", query)\n",
    "\n",
    "def handle_mentions(query):\n",
    "    return re.sub(r\"at_mention:\\((.*?)\\)\", r\"@\\b\\1\\b\", query)\n",
    "\n",
    "def handle_hashtags(query):\n",
    "    return re.sub(r\"hashtag:\\((.*?)\\)\", r\"#\\b\\1\\b\", query)\n",
    "\n",
    "def handle_parentheses(query):\n",
    "    def process_subquery(subquery):\n",
    "        subquery = handle_or(subquery)\n",
    "        subquery = handle_and(subquery)\n",
    "        subquery = handle_not(subquery)\n",
    "        subquery = handle_exact_phrases(subquery)\n",
    "        subquery = handle_near_x(subquery)\n",
    "        subquery = handle_wildcards(subquery)\n",
    "        subquery = handle_question_marks(subquery)\n",
    "        subquery = handle_mentions(subquery)\n",
    "        subquery = handle_hashtags(subquery)\n",
    "        return subquery\n",
    "\n",
    "    stack = []\n",
    "    current_query = \"\"\n",
    "    i = 0\n",
    "\n",
    "    while i < len(query):\n",
    "        if query[i] == \"(\":\n",
    "            stack.append((current_query, i))\n",
    "            current_query = \"\"\n",
    "        elif query[i] == \")\":\n",
    "            last_query, start_pos = stack.pop()\n",
    "            subquery = query[start_pos + 1 : i]\n",
    "            processed_subquery = process_subquery(subquery)\n",
    "            current_query = last_query + f\"(?:{processed_subquery})\"\n",
    "        else:\n",
    "            current_query += query[i]\n",
    "        i += 1\n",
    "\n",
    "    return current_query\n",
    "\n",
    "def process_query(query):\n",
    "    query = handle_parentheses(query)\n",
    "    query = handle_or(query)\n",
    "    query = handle_and(query)\n",
    "    query = handle_not(query)\n",
    "    query = handle_exact_phrases(query)\n",
    "    query = handle_near_x(query)\n",
    "    query = handle_wildcards(query)\n",
    "    query = handle_question_marks(query)\n",
    "    query = handle_mentions(query)\n",
    "    query = handle_hashtags(query)\n",
    "    return query\n",
    "\n",
    "# Example usage\n",
    "query = '''(BB OR \"Beauty Balm\" OR \"Blemish Balm\" OR \"beauty-balm\" OR \"blemish-balm\") NEAR/2 (cream OR creams)'''\n",
    "\n",
    "# Convert query to regex pattern\n",
    "pattern = process_query(query)\n",
    "print(f\"Generated regex pattern: {pattern}\")\n",
    "\n",
    "# Sample data (rows)\n",
    "rows = [\n",
    "    \"I love chocolate and vanilla ice cream Beauty Balm.\",\n",
    "    \"Blue and green are my favorite colors.\",\n",
    "    \"Taste is subjective, but I prefer optimize over optimise.\",\n",
    "    \"Mentioning @doveuk here, and #blue for hashtags.\",\n",
    "]\n",
    "\n",
    "# Apply regex to rows\n",
    "for row in rows:\n",
    "    if re.search(pattern, row, re.IGNORECASE):  # Added re.IGNORECASE for case-insensitive matching\n",
    "        print(f\"Match found: {row}\")\n",
    "    else:\n",
    "        print(f\"No match: {row}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated regex pattern: (?:BB|\\bBeauty\\ Balm\\b|\\bBlemish\\ Balm\\b|\\bbeauty\\-balm\\b|\\bblemish\\-balm\\b) NEAR/2 (?:cream|creams)\n",
      "No match: I love chocolate and vanilla ice cream Beauty Balm.\n",
      "No match: Blue and green are my favorite colors.\n",
      "No match: Taste is subjective, but I prefer optimize over optimise.\n",
      "No match: Mentioning @doveuk here, and #blue for hashtags.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def handle_or(query):\n",
    "    return query.replace(\" OR \", \"|\")\n",
    "\n",
    "def handle_and(query):\n",
    "    return query.replace(\" AND \", \".*\")\n",
    "\n",
    "def handle_not(query):\n",
    "    return re.sub(r\"NOT\\s+(\\w+)\", r\"^(?!.*\\b\\1\\b)\", query)\n",
    "\n",
    "def handle_exact_phrases(query):\n",
    "    return re.sub(r'\"(.*?)\"', lambda m: r\"\\b\" + re.escape(m.group(1)) + r\"\\b\", query)\n",
    "\n",
    "def handle_near_x(query):\n",
    "    near_pattern = re.compile(r'\\((\\w+|\"[^\"]*\")\\s+NEAR/(\\d+)\\s+(\\w+|\"[^\"]*\")\\)')\n",
    "    \n",
    "    def convert_near_pattern(lhs, distance, rhs):\n",
    "        lhs = re.escape(lhs.strip('\"'))\n",
    "        rhs = re.escape(rhs.strip('\"'))\n",
    "        return r'\\b{}\\b(?:\\W+\\w+){{0,{}}}\\W+\\b{}\\b'.format(lhs, distance, rhs)\n",
    "    \n",
    "    while near_pattern.search(query):\n",
    "        match = near_pattern.search(query)\n",
    "        term1, distance, term2 = match.groups()\n",
    "        pattern = convert_near_pattern(term1, int(distance), term2)\n",
    "        query = near_pattern.sub(pattern, query, 1)\n",
    "    \n",
    "    return query\n",
    "\n",
    "def handle_wildcards(query):\n",
    "    return re.sub(r\"(\\w+)\\*\", r\"\\1.*\", query)\n",
    "\n",
    "def handle_question_marks(query):\n",
    "    return re.sub(r\"(\\w+)\\?\", lambda m: f\"{m.group(1)}.\", query)\n",
    "\n",
    "def handle_mentions(query):\n",
    "    return re.sub(r\"at_mention:\\((.*?)\\)\", r\"@\\b\\1\\b\", query)\n",
    "\n",
    "def handle_hashtags(query):\n",
    "    return re.sub(r\"hashtag:\\((.*?)\\)\", r\"#\\b\\1\\b\", query)\n",
    "\n",
    "def handle_parentheses(query):\n",
    "    def process_subquery(subquery):\n",
    "        subquery = handle_or(subquery)\n",
    "        subquery = handle_and(subquery)\n",
    "        subquery = handle_not(subquery)\n",
    "        subquery = handle_exact_phrases(subquery)\n",
    "        subquery = handle_near_x(subquery)\n",
    "        subquery = handle_wildcards(subquery)\n",
    "        subquery = handle_question_marks(subquery)\n",
    "        subquery = handle_mentions(subquery)\n",
    "        subquery = handle_hashtags(subquery)\n",
    "        return subquery\n",
    "\n",
    "    stack = []\n",
    "    current_query = \"\"\n",
    "    i = 0\n",
    "\n",
    "    while i < len(query):\n",
    "        if query[i] == \"(\":\n",
    "            stack.append((current_query, i))\n",
    "            current_query = \"\"\n",
    "        elif query[i] == \")\":\n",
    "            last_query, start_pos = stack.pop()\n",
    "            subquery = query[start_pos + 1 : i]\n",
    "            processed_subquery = process_subquery(subquery)\n",
    "            current_query = last_query + f\"(?:{processed_subquery})\"\n",
    "        else:\n",
    "            current_query += query[i]\n",
    "        i += 1\n",
    "\n",
    "    return current_query\n",
    "\n",
    "def process_query(query):\n",
    "    query = handle_parentheses(query)\n",
    "    query = handle_or(query)\n",
    "    query = handle_and(query)\n",
    "    query = handle_not(query)\n",
    "    query = handle_exact_phrases(query)\n",
    "    query = handle_near_x(query)\n",
    "    query = handle_wildcards(query)\n",
    "    query = handle_question_marks(query)\n",
    "    query = handle_mentions(query)\n",
    "    query = handle_hashtags(query)\n",
    "    return query\n",
    "\n",
    "# Example usage\n",
    "query = '''(BB OR \"Beauty Balm\" OR \"Blemish Balm\" OR \"beauty-balm\" OR \"blemish-balm\") NEAR/2 (cream OR creams)'''\n",
    "\n",
    "# Convert query to regex pattern\n",
    "pattern = process_query(query)\n",
    "print(f\"Generated regex pattern: {pattern}\")\n",
    "\n",
    "# Sample data (rows)\n",
    "rows = [\n",
    "    \"I love chocolate and vanilla ice cream Beauty Balm.\",\n",
    "    \"Blue and green are my favorite colors.\",\n",
    "    \"Taste is subjective, but I prefer optimize over optimise.\",\n",
    "    \"Mentioning @doveuk here, and #blue for hashtags.\",\n",
    "]\n",
    "\n",
    "# Apply regex to rows\n",
    "for row in rows:\n",
    "    if re.search(pattern, row, re.IGNORECASE):  # Added re.IGNORECASE for case-insensitive matching\n",
    "        print(f\"Match found: {row}\")\n",
    "    else:\n",
    "        print(f\"No match: {row}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated regex pattern: (?:(BBBeauty BalBlemish Balbeauty-balblemish-bal) NEAR/2 (?:cream|creams))\n",
      "\n",
      "No match: I love chocolate and vanilla ice cream Beauty Balm.\n",
      "No match: Blue and green are my favorite colors.\n",
      "No match: Taste is subjective, but I prefer optimize over optimise.\n",
      "No match: Mentioning @doveuk here, and #blue for hashtags.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Sample data (rows)\n",
    "rows = [\n",
    "    \"I love chocolate and vanilla ice cream Beauty Balm.\",\n",
    "    \"Blue and green are my favorite colors.\",\n",
    "    \"Taste is subjective, but I prefer optimize over optimise.\",\n",
    "    \"Mentioning @doveuk here, and #blue for hashtags.\",\n",
    "]\n",
    "\n",
    "# Example query\n",
    "query = \"\"\"((BB OR \"Beauty Balm\" OR \"Blemish Balm\" OR \"beauty-balm\" OR \"blemish-balm\") NEAR/2 (cream OR creams))\"\"\"\n",
    "\n",
    "def convert_to_regex(query):\n",
    "    # Replace OR, AND, NOT with regex equivalents\n",
    "    query = query.replace(\" OR \", \"|\").replace(\" AND \", \".*\").replace(\"NOT \", \"^(?!.*\")\n",
    "    \n",
    "    # Handle exact phrases (those inside double quotes)\n",
    "    query = re.sub(r'\"(.*?)\"', r'\\b\\1\\b', query)\n",
    "    \n",
    "    # Handle parentheses\n",
    "    query = re.sub(r'\\((.*?)\\)', lambda m: f'(?:{convert_to_regex(m.group(1))})', query)\n",
    "    \n",
    "    return query\n",
    "\n",
    "def handle_near_x(query):\n",
    "    # Match patterns like `\"phrase1\" NEAR/x \"phrase2\"`\n",
    "    near_pattern = re.compile(r'(\".*?\"|\\w+)\\s+NEAR/(\\d+)\\s+(\".*?\"|\\w+)')\n",
    "    while near_pattern.search(query):\n",
    "        match = near_pattern.search(query)\n",
    "        phrase1, distance, phrase2 = match.groups()\n",
    "        phrase1 = phrase1.strip('\"')\n",
    "        phrase2 = phrase2.strip('\"')\n",
    "        pattern = r'\\b{}\\b(?:\\W+\\w+){{0,{}}}\\W+\\b{}\\b'.format(phrase1, int(distance), phrase2)\n",
    "        query = near_pattern.sub(pattern, query, 1)\n",
    "    return query\n",
    "\n",
    "def handle_wildcards_and_questions(query):\n",
    "    query = re.sub(r'(\\w+)\\*', r'\\1.*', query)  # Handle wildcards\n",
    "    query = re.sub(r'(\\w+)\\?', lambda m: f'{m.group(1)}[a-zA-Z]', query)  # Handle question marks\n",
    "    return query\n",
    "\n",
    "def handle_mentions_hashtags(query):\n",
    "    query = re.sub(r'at_mention:\\((.*?)\\)', r'@\\b\\1\\b', query)\n",
    "    query = re.sub(r'hashtag:\\((.*?)\\)', r'#\\b\\1\\b', query)\n",
    "    return query\n",
    "\n",
    "def process_query(query):\n",
    "    query = convert_to_regex(query)\n",
    "    query = handle_near_x(query)\n",
    "    query = handle_wildcards_and_questions(query)\n",
    "    query = handle_mentions_hashtags(query)\n",
    "    return query\n",
    "\n",
    "# Apply regex to rows\n",
    "pattern = process_query(query)\n",
    "print(f\"Generated regex pattern: {pattern}\\n\")\n",
    "\n",
    "for row in rows:\n",
    "    if re.search(pattern, row, re.IGNORECASE):  # Added re.IGNORECASE for case-insensitive matching\n",
    "        print(f\"Match found: {row}\")\n",
    "    else:\n",
    "        print(f\"No match: {row}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(BB|\"Beauty Balm\"|\"Blemish Balm\"|\"beauty-balm\"|\"blemish-balm\") NEAR/2 (cream|creams)\n",
      "(BB|\"Beauty Balm\"|\"Blemish Balm\"|\"beauty-balm\"|\"blemish-balm\") NEAR/2 (cream|creams)\n",
      "(BB|\"Beauty Balm\"|\"Blemish Balm\"|\"beauty-balm\"|\"blemish-balm\") NEAR/2 (cream|creams)\n",
      "(BBBeauty BalBlemish Balbeauty-balblemish-bal) NEAR/2 (cream|creams)\n",
      "(BBBeauty BalBlemish Balbeauty-balblemish-bal) NEAR/2 (cream|creams)\n",
      "(BBBeauty BalBlemish Balbeauty-balblemish-bal) NEAR/2 (cream|creams)\n",
      "(BBBeauty BalBlemish Balbeauty-balblemish-bal) NEAR/2 (cream|creams)\n",
      "(BBBeauty BalBlemish Balbeauty-balblemish-bal) NEAR/2 (cream|creams)\n",
      "(BBBeauty BalBlemish Balbeauty-balblemish-bal) NEAR/2 (cream|creams)\n",
      "Generated regex pattern: (BBBeauty BalBlemish Balbeauty-balblemish-bal) NEAR/2 (cream|creams)\n",
      "\n",
      "No match: I love chocolate and vanilla ice cream Beauty Balm.\n",
      "No match: Blue and green are my favorite colors.\n",
      "No match: Taste is subjective, but I prefer optimize over optimise.\n",
      "No match: Mentioning @doveuk here, and #blue for hashtags.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Sample data (rows)\n",
    "rows = [\n",
    "    \"I love chocolate and vanilla ice cream Beauty Balm.\",\n",
    "    \"Blue and green are my favorite colors.\",\n",
    "    \"Taste is subjective, but I prefer optimize over optimise.\",\n",
    "    \"Mentioning @doveuk here, and #blue for hashtags.\",\n",
    "]\n",
    "\n",
    "# Example query\n",
    "query = \"\"\"(BB OR \"Beauty Balm\" OR \"Blemish Balm\" OR \"beauty-balm\" OR \"blemish-balm\") NEAR/2 (cream OR creams)\"\"\"\n",
    "\n",
    "def handle_or(query):\n",
    "    return query.replace(\" OR \", \"|\")\n",
    "\n",
    "def handle_and(query):\n",
    "    return query.replace(\" AND \", \".*\")\n",
    "\n",
    "def handle_not(query):\n",
    "    return re.sub(r'NOT\\s+(\\w+)', r'^(?!.*\\b\\1\\b)', query)\n",
    "\n",
    "def handle_exact_phrases(query):\n",
    "    return re.sub(r'\"(.*?)\"', r'\\b\\1\\b', query)\n",
    "\n",
    "def handle_parentheses(query):\n",
    "    # Recursively handle nested queries inside parentheses\n",
    "    while '(' in query:\n",
    "        query = re.sub(r'\\(([^()]+)\\)', lambda m: f'(?:{process_query(m.group(1))})', query)\n",
    "    return query\n",
    "\n",
    "def handle_near_x(query):\n",
    "    near_pattern = re.compile(r'(\\w+|\"[^\"]*\")\\s+NEAR/(\\d+)\\s+(\\w+|\"[^\"]*\")')\n",
    "    while near_pattern.search(query):\n",
    "        match = near_pattern.search(query)\n",
    "        term1, distance, term2 = match.groups()\n",
    "        term1 = term1.strip('\"')\n",
    "        term2 = term2.strip('\"')\n",
    "        pattern = r'\\b{}\\b(?:\\W+\\w+){{0,{}}}\\W+\\b{}\\b'.format(term1, int(distance), term2)\n",
    "        query = near_pattern.sub(pattern, query, 1)\n",
    "    return query\n",
    "\n",
    "def handle_wildcards(query):\n",
    "    return re.sub(r'(\\w+)\\*', r'\\1.*', query)\n",
    "\n",
    "def handle_question_marks(query):\n",
    "    return re.sub(r'(\\w+)\\?', lambda m: f'{m.group(1)}.', query)\n",
    "\n",
    "def handle_mentions(query):\n",
    "    return re.sub(r'at_mention:\\((.*?)\\)', r'@\\b\\1\\b', query)\n",
    "\n",
    "def handle_hashtags(query):\n",
    "    return re.sub(r'hashtag:\\((.*?)\\)', r'#\\b\\1\\b', query)\n",
    "\n",
    "def process_query(query):\n",
    "    query = handle_or(query)\n",
    "    print(query)\n",
    "    query = handle_and(query)\n",
    "    print(query)\n",
    "    query = handle_not(query)\n",
    "    print(query)\n",
    "    query = handle_exact_phrases(query)\n",
    "    print(query)\n",
    "    #query = handle_parentheses(query)\n",
    "    query = handle_near_x(query)\n",
    "    print(query)\n",
    "    query = handle_wildcards(query)\n",
    "    print(query)\n",
    "    query = handle_question_marks(query)\n",
    "    print(query)\n",
    "    query = handle_mentions(query)\n",
    "    print(query)\n",
    "    query = handle_hashtags(query)\n",
    "    print(query)\n",
    "    return query\n",
    "\n",
    "# Apply regex to rows\n",
    "pattern = process_query(query)\n",
    "print(f\"Generated regex pattern: {pattern}\\n\")\n",
    "\n",
    "for row in rows:\n",
    "    if re.search(pattern, row, re.IGNORECASE):  # Added re.IGNORECASE for case-insensitive matching\n",
    "        print(f\"Match found: {row}\")\n",
    "    else:\n",
    "        print(f\"No match: {row}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 're' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-8f82916b6e69>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;34m'('\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mquery\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'----'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mquery\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'\\(([^()]+)\\)'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34mf'(?:{process_query(m.group(1))})'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 're' is not defined"
     ]
    }
   ],
   "source": [
    "query = \"\"\"(BB OR \"Beauty Balm\" OR \"Blemish Balm\" OR \"beauty-balm\" OR \"blemish-balm\") NEAR/2 (cream OR creams)\"\"\"\n",
    "\n",
    "while '(' in query:\n",
    "    print('----')\n",
    "    query = re.sub(r'\\(([^()]+)\\)', lambda m: f'(?:{process_query(m.group(1))})', query)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NEAR/x (blue NEAR/3 green):\n",
    "Regex Pattern: \\bblue\\b(?:\\W+\\w+){0,3}\\W+\\bgreen\\b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The query contains the NEAR/x operator.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Example query\n",
    "query = \"\"\"(BB OR \"Beauty Balm\" OR \"Blemish Balm\" OR \"beauty-balm\" OR \"blemish-balm\") NEAR/2 (cream OR creams)\"\"\"\n",
    "\n",
    "def contains_near_operator(query):\n",
    "    # Regular expression to match the NEAR/x pattern\n",
    "    near_pattern = re.compile(r'\\bNEAR/\\d+\\b')\n",
    "\n",
    "    # Search for the pattern in the query\n",
    "    match = near_pattern.search(query)\n",
    "\n",
    "    # Return True if the pattern is found, otherwise False\n",
    "    return match is not None\n",
    "\n",
    "# Check if the NEAR/x operator exists in the query\n",
    "if contains_near_operator(query):\n",
    "    print(\"The query contains the NEAR/x operator.\")\n",
    "else:\n",
    "    print(\"The query does not contain the NEAR/x operator.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "near_strings = re.findall(r'(\\(?([^\\)\\(]*?)\\)?(?:\\s)((?:NEAR\\/)([0-9]+))(?:\\s)\\(?(.*?)\\))', query,\n",
    "                              flags=re.UNICODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KRILLIN\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.4)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    }
   ],
   "source": [
    "near_strings\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_python_operators(query):\n",
    "    \"\"\"\n",
    "    Takes the query with symbol operators and replace with python equivalent\n",
    "    so can be evaluated by eval() function\n",
    "    :param query: The input query\n",
    "    :return query: The query with operators replaced with Python operators (and, not, or) so that Python can evaluate\n",
    "     the query\n",
    "    \"\"\"\n",
    "    query = re.sub(r'\\!\\!', 'not', query, flags=re.UNICODE)\n",
    "    query = re.sub(r'\\&\\&', 'and', query, flags=re.UNICODE)\n",
    "    query = re.sub(r'\\|\\|', 'or', query, flags=re.UNICODE)\n",
    "\n",
    "    return query\n",
    "\n",
    "\n",
    "quoted_word_pattern = re.compile(u'\"(.*?)\"', flags=re.UNICODE)\n",
    "question_mark_pattern = re.compile(r'\\w+?\\.[a-z]*', flags=re.UNICODE)\n",
    "def parse_near(parsed_query, input_text):\n",
    "    \"\"\"\n",
    "    Takes a NEAR statement, evaluates it and returns the full query with the parsed NEAR statement.\n",
    "    :param parsed_query: The query associated with a topic\n",
    "    :param input_text: The input text\n",
    "    :return parsed_query: The output query once it has been parsed with the NEAR operator\n",
    "    \"\"\"\n",
    "    parsed_query = parsed_query.lower()\n",
    "    parsed_query = parsed_query.replace('?', '.')\n",
    "\n",
    "    # Find all the near statements in the query\n",
    "    # \\(?([^\\)\\(]*?)\\)?(?:\\s)((?:near\\/)([0-9]+))(?:\\s)\\(?(.*?)\\)  (\\(\\(?(.*?)\\)?(?:\\s)((?:near\\/)([0-9]+))(?:\\s)\\(?(.*?)\\)?\\))\n",
    "    near_strings = re.findall(r'(\\(?([^\\)\\(]*?)\\)?(?:\\s)((?:near\\/)([0-9]+))(?:\\s)\\(?(.*?)\\))', parsed_query,\n",
    "                              flags=re.UNICODE)\n",
    "\n",
    "    for nstring in near_strings:\n",
    "        # Strip whitespace\n",
    "        words = [word.strip() for word in nstring]\n",
    "\n",
    "        # Get the number after NEAR/ in the query\n",
    "        sepdist = words[3]\n",
    "\n",
    "        # Get the words in the LHS of the query\n",
    "        lhs = words[1]\n",
    "\n",
    "        # Get the words in the RHS of the query\n",
    "        rhs = words[4]\n",
    "\n",
    "        keywords = ['(', ')', u'||', u'&&', u'!!']\n",
    "\n",
    "        # Find quoted phrases\n",
    "        quoted_left = quoted_word_pattern.findall(lhs)\n",
    "        quoted_right = quoted_word_pattern.findall(rhs)\n",
    "        n_quoted_left = []\n",
    "        for w in quoted_left:\n",
    "            n_quoted_left.append('\"' + w + '\"')\n",
    "        quoted_left = n_quoted_left\n",
    "        n_quoted_right = []\n",
    "        for w in quoted_right:\n",
    "            n_quoted_right.append('\"' + w + '\"')\n",
    "        quoted_right = n_quoted_right\n",
    "        # Extract words to match with input text before and after near and append quoted phrases\n",
    "        words_left = [w for w in word_tokenize(re.sub(u'\"(.*?)\"', '', lhs, flags=re.UNICODE)) if\n",
    "                      w.lower() not in keywords] + quoted_left\n",
    "        words_right = [w for w in re.sub(u'\"(.*?)\"', '', rhs, flags=re.UNICODE).split() if\n",
    "                       w not in keywords] + quoted_right\n",
    "        \n",
    "        # We sort them so quoted words come first to prevent issue where words inside quoted words aren't replaced\n",
    "        words_left = sorted(words_left)\n",
    "        words_right = sorted(words_right)\n",
    "        \n",
    "        words_near = []\n",
    "\n",
    "        # Appending regex symbol /w to match any word character(s) before the next space\n",
    "        for a in words_left:\n",
    "            for b in words_right:\n",
    "                if a[-1:] == '*':\n",
    "                    match_a = re.escape(re.sub(r'\\*', '', a, flags=re.UNICODE)) + r'\\w*'\n",
    "                else:\n",
    "                    question_mark = question_mark_pattern.findall(a)\n",
    "\n",
    "                    if a in question_mark:\n",
    "                        match_a = a\n",
    "                    else:\n",
    "                        match_a = re.escape(a)\n",
    "\n",
    "                if b[-1:] == '*':\n",
    "                    match_b = re.escape(re.sub(r'\\*', '', b, flags=re.UNICODE)) + r'\\w*'\n",
    "                else:\n",
    "                    question_mark = question_mark_pattern.findall(b)\n",
    "\n",
    "                    if b in question_mark:\n",
    "                        match_b = b\n",
    "                    else:\n",
    "                        match_b = re.escape(b)\n",
    "\n",
    "                match_a_nq = match_a.strip('\"')\n",
    "                match_b_nq = match_b.strip('\"')\n",
    "\n",
    "                # Check distance between each pair of words on each side of NEAR is less than required\n",
    "                m = re.search(r'\\b(?:' + match_a_nq + r'\\W+(?:\\w+\\W+){0,' + re.escape(\n",
    "                    sepdist) + r'}?' + match_b_nq + r'|' + match_b_nq + r'\\W+(?:\\w+\\W+){0,' + re.escape(\n",
    "                    sepdist) + r'}?' + match_a_nq + r')\\b', input_text, flags=re.UNICODE)\n",
    "\n",
    "                if m:\n",
    "                    x = True\n",
    "\n",
    "                else:\n",
    "                    x = False\n",
    "\n",
    "                words_near.append((a, b, x))\n",
    "\n",
    "        eval_left = lhs.lower()\n",
    "\n",
    "        # for each word in query on lhs, check it satisfies condition on rhs\n",
    "        for word_left in words_left:\n",
    "\n",
    "            match_dict = {wn[1]: wn[2] for wn in words_near if wn[0] == word_left}\n",
    "\n",
    "            eval_right = rhs\n",
    "\n",
    "            for key, value in match_dict.items():\n",
    "                if key[0] == '\"':\n",
    "                    # We match direct on key as we add in the quotes in quoted_right\n",
    "                    eval_right = re.sub(key, str(value), eval_right, flags=re.UNICODE)\n",
    "                else:\n",
    "                    eval_right = re.sub(r'\\b' + key + r'\\b', str(value), eval_right, flags=re.UNICODE)\n",
    "\n",
    "            # Replace asterisks so that each side can be evaluated\n",
    "            eval_left = re.sub(r'\\*', '', eval_left, flags=re.UNICODE)\n",
    "            eval_right = re.sub(r'\\*', '', eval_right, flags=re.UNICODE)\n",
    "            eval_left = convert_to_python_operators(eval_left)\n",
    "            eval_right = convert_to_python_operators(eval_right)\n",
    "            eval_right = eval_right.replace('\"', '')\n",
    "\n",
    "\n",
    "            if word_left[0] == '\"':\n",
    "                # We match direct on key as we add in the quotes in quoted_left\n",
    "                eval_left = re.sub(word_left, str(eval(eval_right)), eval_left, flags=re.UNICODE)\n",
    "            else:\n",
    "                eval_left = re.sub(r'\\b' + word_left + r'\\b', str(eval(eval_right)), eval_left, flags=re.UNICODE)\n",
    "\n",
    "        eval_left = eval_left.replace('\"', '')\n",
    "\n",
    "        final_eval = eval(eval_left)\n",
    "\n",
    "        parsed_query = parsed_query.replace(nstring[0], str(final_eval))\n",
    "\n",
    "    return parsed_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "parsed_query = '(apple NEAR/2 orange)'\n",
    "input_text = 'I ate an apple and an orange yesterday.'\n",
    "\n",
    "result = parse_near(parsed_query, input_text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\KRILLIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\KRILLIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Falses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-c9b4b607c889>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[1;31m# Apply regex to rows\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrows\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m     \u001b[0mpattern\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocess_query\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Generated regex pattern: {pattern}\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIGNORECASE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Added re.IGNORECASE for case-insensitive matching\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-31-c9b4b607c889>\u001b[0m in \u001b[0;36mprocess_query\u001b[1;34m(query, text)\u001b[0m\n\u001b[0;32m    126\u001b[0m     \u001b[0mquery\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandle_exact_phrases\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m     \u001b[1;31m#query = handle_parentheses(query)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m     \u001b[0mquery\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparse_near\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Using parse_near here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m     \u001b[0mquery\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandle_wildcards\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[0mquery\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandle_question_marks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-31-c9b4b607c889>\u001b[0m in \u001b[0;36mparse_near\u001b[1;34m(parsed_query, input_text)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0meval_left\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_left\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meval_right\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_left\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUNICODE\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mword_left\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'\"'\u001b[0m \u001b[1;32melse\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m                         \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'\\b'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mword_left\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34mr'\\b'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meval_right\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_left\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUNICODE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[0meval_left\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meval_left\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\"'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Falses' is not defined"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "\n",
    "# Ensure NLTK's tokenizer is ready\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Sample data (rows)\n",
    "rows = [\n",
    "    \"I love chocolate and vanilla ice cream Beauty Balm.\",\n",
    "    \"Blue and green are my favorite colors.\",\n",
    "    \"Taste is subjective, but I prefer optimize over optimise.\",\n",
    "    \"Mentioning @doveuk here, and #blue for hashtags.\",\n",
    "]\n",
    "\n",
    "# Example query\n",
    "query = \"\"\"(BB OR \"Beauty Balm\" OR \"Blemish Balm\" OR \"beauty-balm\" OR \"blemish-balm\") NEAR/2 (cream OR creams)\"\"\"\n",
    "\n",
    "def handle_or(query):\n",
    "    return query.replace(\" OR \", \"|\")\n",
    "\n",
    "def handle_and(query):\n",
    "    return query.replace(\" AND \", \".*\")\n",
    "\n",
    "def handle_not(query):\n",
    "    return re.sub(r'NOT\\s+(\\w+)', r'^(?!.*\\b\\1\\b)', query)\n",
    "\n",
    "def handle_exact_phrases(query):\n",
    "    return re.sub(r'\"(.*?)\"', r'\\b\\1\\b', query)\n",
    "\n",
    "def handle_parentheses(query):\n",
    "    while '(' in query:\n",
    "        query = re.sub(r'\\(([^()]+)\\)', lambda m: f'(?:{process_query(m.group(1))})', query)\n",
    "    return query\n",
    "\n",
    "def handle_wildcards(query):\n",
    "    return re.sub(r'(\\w+)\\*', r'\\1.*', query)\n",
    "\n",
    "def handle_question_marks(query):\n",
    "    return re.sub(r'(\\w+)\\?', lambda m: f'{m.group(1)}.', query)\n",
    "\n",
    "def handle_mentions(query):\n",
    "    return re.sub(r'at_mention:\\((.*?)\\)', r'@\\b\\1\\b', query)\n",
    "\n",
    "def handle_hashtags(query):\n",
    "    return re.sub(r'hashtag:\\((.*?)\\)', r'#\\b\\1\\b', query)\n",
    "\n",
    "def convert_to_python_operators(query):\n",
    "    query = re.sub(r'\\!\\!', 'not', query, flags=re.UNICODE)\n",
    "    query = re.sub(r'\\&\\&', 'and', query, flags=re.UNICODE)\n",
    "    query = re.sub(r'\\|\\|', 'or', query, flags=re.UNICODE)\n",
    "    return query\n",
    "\n",
    "quoted_word_pattern = re.compile(u'\"(.*?)\"', flags=re.UNICODE)\n",
    "question_mark_pattern = re.compile(r'\\w+?\\.[a-z]*', flags=re.UNICODE)\n",
    "\n",
    "def parse_near(parsed_query, input_text):\n",
    "    parsed_query = parsed_query.lower().replace('?', '.')\n",
    "    near_strings = re.findall(r'(\\(?([^\\)\\(]*?)\\)?(?:\\s)((?:near\\/)([0-9]+))(?:\\s)\\(?(.*?)\\))', parsed_query,\n",
    "                              flags=re.UNICODE)\n",
    "    for nstring in near_strings:\n",
    "        words = [word.strip() for word in nstring]\n",
    "        sepdist = words[3]\n",
    "        lhs = words[1]\n",
    "        rhs = words[4]\n",
    "        keywords = ['(', ')', u'||', u'&&', u'!!']\n",
    "\n",
    "        quoted_left = quoted_word_pattern.findall(lhs)\n",
    "        quoted_right = quoted_word_pattern.findall(rhs)\n",
    "        n_quoted_left = ['\"' + w + '\"' for w in quoted_left]\n",
    "        n_quoted_right = ['\"' + w + '\"' for w in quoted_right]\n",
    "        quoted_left = n_quoted_left\n",
    "        quoted_right = n_quoted_right\n",
    "\n",
    "        words_left = [w for w in word_tokenize(re.sub(u'\"(.*?)\"', '', lhs, flags=re.UNICODE)) if\n",
    "                      w.lower() not in keywords] + quoted_left\n",
    "        words_right = [w for w in re.sub(u'\"(.*?)\"', '', rhs, flags=re.UNICODE).split() if\n",
    "                       w not in keywords] + quoted_right\n",
    "\n",
    "        words_left = sorted(words_left)\n",
    "        words_right = sorted(words_right)\n",
    "        words_near = []\n",
    "\n",
    "        for a in words_left:\n",
    "            for b in words_right:\n",
    "                match_a = re.escape(re.sub(r'\\*', '', a, flags=re.UNICODE)) + r'\\w*' if a[-1:] == '*' else re.escape(a)\n",
    "                match_b = re.escape(re.sub(r'\\*', '', b, flags=re.UNICODE)) + r'\\w*' if b[-1:] == '*' else re.escape(b)\n",
    "                match_a_nq = match_a.strip('\"')\n",
    "                match_b_nq = match_b.strip('\"')\n",
    "\n",
    "                m = re.search(r'\\b(?:' + match_a_nq + r'\\W+(?:\\w+\\W+){0,' + re.escape(sepdist) + r'}?' + match_b_nq +\n",
    "                              r'|' + match_b_nq + r'\\W+(?:\\w+\\W+){0,' + re.escape(sepdist) + r'}?' + match_a_nq + r')\\b',\n",
    "                              input_text, flags=re.UNICODE)\n",
    "                x = True if m else False\n",
    "                words_near.append((a, b, x))\n",
    "\n",
    "        eval_left = lhs.lower()\n",
    "\n",
    "        for word_left in words_left:\n",
    "            match_dict = {wn[1]: wn[2] for wn in words_near if wn[0] == word_left}\n",
    "            eval_right = rhs\n",
    "\n",
    "            for key, value in match_dict.items():\n",
    "                eval_right = re.sub(key, str(value), eval_right, flags=re.UNICODE) if key[0] == '\"' else \\\n",
    "                            re.sub(r'\\b' + key + r'\\b', str(value), eval_right, flags=re.UNICODE)\n",
    "\n",
    "            eval_left = re.sub(r'\\*', '', eval_left, flags=re.UNICODE)\n",
    "            eval_right = re.sub(r'\\*', '', eval_right, flags=re.UNICODE)\n",
    "            eval_left = convert_to_python_operators(eval_left)\n",
    "            eval_right = convert_to_python_operators(eval_right)\n",
    "            eval_right = eval_right.replace('\"', '')\n",
    "\n",
    "            eval_left = re.sub(word_left, str(eval(eval_right)), eval_left, flags=re.UNICODE) if word_left[0] == '\"' else \\\n",
    "                        re.sub(r'\\b' + word_left + r'\\b', str(eval(eval_right)), eval_left, flags=re.UNICODE)\n",
    "\n",
    "        eval_left = eval_left.replace('\"', '')\n",
    "        final_eval = eval(eval_left)\n",
    "        parsed_query = parsed_query.replace(nstring[0], str(final_eval))\n",
    "\n",
    "    return parsed_query\n",
    "\n",
    "def process_query(query, text):\n",
    "    query = handle_or(query)\n",
    "    query = handle_and(query)\n",
    "    query = handle_not(query)\n",
    "    query = handle_exact_phrases(query)\n",
    "    #query = handle_parentheses(query)\n",
    "    query = parse_near(query, text)  # Using parse_near here\n",
    "    query = handle_wildcards(query)\n",
    "    query = handle_question_marks(query)\n",
    "    query = handle_mentions(query)\n",
    "    query = handle_hashtags(query)\n",
    "    return query\n",
    "\n",
    "# Apply regex to rows\n",
    "for row in rows:\n",
    "    pattern = process_query(query, row)\n",
    "    print(f\"Generated regex pattern: {pattern}\\n\")\n",
    "    if re.search(pattern, row, re.IGNORECASE):  # Added re.IGNORECASE for case-insensitive matching\n",
    "        print(f\"Match found: {row}\")\n",
    "    else:\n",
    "        print(f\"No match: {row}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
